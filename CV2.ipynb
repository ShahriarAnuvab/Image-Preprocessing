{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpRQThGbROP5",
        "outputId": "8f340749-82f7-4a5f-b54b-ad02815bfc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######### PRE - PROCESSING ################\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Define image size and output directory\n",
        "img_width, img_height = 224, 224\n",
        "output_dir = ('gdrive/My Drive/TEST')\n",
        "\n",
        "# Define the pre-processing pipeline\n",
        "def pre_process_image(image_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Apply thresholding\n",
        "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "\n",
        "    # Find and draw contours\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        if w > 10 and h > 10:\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "    # Resize the image\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "    return img\n",
        "\n",
        "# Load the raw image dataset and pre-process each image\n",
        "raw_data_dir = ('gdrive/My Drive/TEST/DATA')\n",
        "for filename in os.listdir(raw_data_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(raw_data_dir, filename)\n",
        "        pre_processed_image = pre_process_image(image_path)\n",
        "\n",
        "        # Save the pre-processed image to the output directory\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "        cv2.imwrite(output_path, pre_processed_image)\n"
      ],
      "metadata": {
        "id": "HksqLnV0RRTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import os\n",
        "\n",
        "# # Define image size and output directory\n",
        "# img_width, img_height = 224, 224\n",
        "# output_dir = 'gdrive/My Drive/TEST/YOLO5'\n",
        "\n",
        "# # Define the pre-processing pipeline\n",
        "# def pre_process_image(image_path):\n",
        "#     # Load the image\n",
        "#     img = cv2.imread(image_path)\n",
        "\n",
        "#     # Convert to grayscale\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # Apply Gaussian blur\n",
        "#     blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "#     # Apply thresholding\n",
        "#     _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "\n",
        "#     # Find and draw contours\n",
        "#     contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#     for contour in contours:\n",
        "#         x, y, w, h = cv2.boundingRect(contour)\n",
        "#         if w > 10 and h > 10:\n",
        "#             cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "#             cv2.putText(img, 'Car', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "#     # Resize the image\n",
        "#     img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "#     return img\n",
        "\n",
        "# # Load the raw image dataset and pre-process each image\n",
        "# raw_data_dir = 'gdrive/My Drive/TEST'\n",
        "# for filename in os.listdir(raw_data_dir):\n",
        "#     if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "#         image_path = os.path.join(raw_data_dir, filename)\n",
        "#         pre_processed_image = pre_process_image(image_path)\n",
        "\n",
        "#         # Save the pre-processed image to the output directory\n",
        "#         output_path = os.path.join(output_dir, filename)\n",
        "#         cv2.imwrite(output_path, pre_processed_image)\n",
        "# results.show()"
      ],
      "metadata": {
        "id": "5l4vrU5Qk7_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load YOLOv3 weights and configuration\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "\n",
        "# Load COCO class labels\n",
        "classes = []\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Generate random colors for each class label\n",
        "np.random.seed(42)\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "# Path to directory containing input images\n",
        "input_dir = 'gdrive/My Drive/TEST'\n",
        "\n",
        "# Path to directory to save output images\n",
        "output_dir = 'gdrive/My Drive/TEST/YOLO5'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Iterate over input images\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Load image\n",
        "        image = cv2.imread(os.path.join(input_dir, filename))\n",
        "\n",
        "        # Get image dimensions\n",
        "        height, width, _ = image.shape\n",
        "\n",
        "        # Convert image to blob format for input to neural network\n",
        "        blob = cv2.dnn.blobFromImage(image, 1/255, (416, 416), swapRB=True, crop=False)\n",
        "\n",
        "        # Set input to neural network\n",
        "        net.setInput(blob)\n",
        "\n",
        "        # Run forward pass through network\n",
        "        outs = net.forward(net.getUnconnectedOutLayersNames())\n",
        "\n",
        "        # Initialize empty lists for boxes, confidences, and class IDs\n",
        "        boxes = []\n",
        "        confidences = []\n",
        "        classIDs = []\n",
        "\n",
        "        # Iterate over each detection output\n",
        "        for out in outs:\n",
        "            # Iterate over each detection in output\n",
        "            for detection in out:\n",
        "                # Extract class ID and confidence of current detection\n",
        "                scores = detection[5:]\n",
        "                classID = np.argmax(scores)\n",
        "                confidence = scores[classID]\n",
        "\n",
        "                # Filter out weak detections\n",
        "                if confidence > 0.5:\n",
        "                    # Calculate bounding box coordinates relative to image size\n",
        "                    box = detection[0:4] * np.array([width, height, width, height])\n",
        "                    (centerX, centerY, bwidth, bheight) = box.astype(\"int\")\n",
        "                    x = int(centerX - (bwidth / 2))\n",
        "                    y = int(centerY - (bheight / 2))\n",
        "\n",
        "                    # Add box, confidence, and class ID to respective lists\n",
        "                    boxes.append([x, y, int(bwidth), int(bheight)])\n",
        "                    confidences.append(float(confidence))\n",
        "                    classIDs.append(classID)\n",
        "\n",
        "        # Apply non-maxima suppression to remove overlapping boxes\n",
        "        indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "        # Iterate over indices after non-maxima suppression\n",
        "        for i in indices:\n",
        "            #i = i[0]\n",
        "            box = boxes[i]\n",
        "            x, y, w, h = box\n",
        "            color = colors[classIDs[i]]\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "            text = f\"{classes[classIDs[i]]}: {confidences[i]:.2f}\"\n",
        "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Save output image\n",
        "        cv2.imwrite(os.path.join(output_dir, filename), image)\n"
      ],
      "metadata": {
        "id": "MFSs9j1e6oFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the VGG16 model\n",
        "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new classifier on top of the pre-trained model\n",
        "x = Flatten()(vgg16.output)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "predictions = Dense(1000, activation='softmax')(x)\n",
        "\n",
        "# Define the new model\n",
        "model = Model(inputs=vgg16.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "O7YW_RX39U9P",
        "outputId": "c34b0c20-ac91-49ad-8411-2859f436a777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    }
  ]
}